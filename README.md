# CLA-Jinsei.ai

https://jinsei.ai/cla

Spreadsheet data mapping automation and turbocharged GPT/Grok extension SaaS.

Solutions powered by Jax Tensorflow and GPT/Grok. 

## CLA Problem:

Automating data transformations for every accounting statement, extended GPT interface, and on-chain trade gains audits. 

# CLA Solutions 

## 1) GPT/Grok Turbocharged: Upload multiple files with automated formatting for mutliple spreadsheets

### Upload multiple files within GPT chat and have them automtically formatted and synced with the CLA tool suite. 

### Assistant can take multiple file uploads and output the files to the CLA tool suite in a standardized format.

- Boilerplate Prompt (query syntax) Training: https://github.com/HenrikMoe/jinsei.ai-sbrm-rdf-llm-UI/blob/main/backend/server.js
- Boilerplate Classification Training: https://github.com/PortalToBlockchainOrganization/CryptoCountAI/blob/master/typeModelResult1.py
- Integrate CLA DB Queries to Taxonomy Element pairings 
- Needs collections of client ROI reports required by CLA

## 2) Multi-SpreadSheet Data Formatting Automation

- excel sheet content mapping to CLA audit suite and Jinsei chat  
- needs investment statements sets from compatible and not compatible excel sheets with the current CLA transformation pipeline

Sequence-to-Sequence TF JAX service for automating multi-spreadsheet content position format standardization for digestion by audit and other programs within CLA and within this joint venture.

## 3) Blockchain Investing Gains On-Chain Data Audit

- audit with bank statements and on chain data for verification of trading gains
- delivered with chat service and through the CLA data interface

### Service Interface/DevOps

Container routing, REST transfer protocol preference.  

### Service StartUp: Set Env & Run Models

Boilerplate Sequence to Sequence model: https://github.com/HenrikMoe/LodgeIt-JinseiAI/edit/main/xmlSeq2Seq.py

edit this

startup:
Navigate to the directory where you want to create the virtual environment
```linux
# cd (project root) 
```
Create a virtual environment (you can choose any name, here we use "venv")
```linux
python3 -m venv venv
```

Activate the virtual environment
```linux
source venv/bin/activate
```

Install required packages
```linux
pip install numpy TFANN matplotlib scikit-learn tensorflow
```

Make sure you are in the directory containing your script
```linux
cd (rn the csv and the py file are in Machine)
```
Run the script
```linux
python chat3deriv.py
```

Training Data ReadMe: https://

```python
# Training data organization
training_data = [
    {"input_xml": "<input_xml_1>", "target_xml": "<target_xml_1>"},
    {"input_xml": "<input_xml_2>", "target_xml": "<target_xml_2>"},
    # Add more examples as needed
]

# Extract input and target sequences from training data
input_xml_data = [example["input_xml"] for example in training_data]
target_xml_data = [example["target_xml"] for example in training_data]

```



